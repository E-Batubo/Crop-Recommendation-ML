{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c1c3cd8d-ff9c-4e36-8cb4-73c8125414be",
   "metadata": {},
   "source": [
    "# Crop Recommendation Using Machine Learning\n",
    "\n",
    "This project recommends the best crop for cultivation based on certain soil and weather conditions. The goal is to help farmers make data-driven decisions and improve agricultural productivity.\n",
    "\n",
    "### Objectives:\n",
    "- Use soil and weather parameters to predict the most suitable crop.\n",
    "- Build and evaluate a machine learning model for accurate predictions.\n",
    "\n",
    "**Dataset**: [Crop Recommendation Dataset](https://www.kaggle.com/datasets/atharvaingle/crop-recommendation-dataset) by Atharva Ingle."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cdc7ec7-c3c5-4360-bb85-d82b533c4360",
   "metadata": {},
   "source": [
    "### Dataset Overview"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "93b1c89f-5b4b-4408-973b-77ce9f5a04f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "580878e2-4bf1-42d9-af35-d5e6f65b5fb4",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '../input/crop-recommendation-dataset/Crop_recommendation.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[5], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Load the dataset\u001b[39;00m\n\u001b[0;32m      2\u001b[0m file_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m../input/crop-recommendation-dataset/Crop_recommendation.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m----> 3\u001b[0m crop_data \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(file_path)\n\u001b[0;32m      5\u001b[0m \u001b[38;5;66;03m# Display the first few rows\u001b[39;00m\n\u001b[0;32m      6\u001b[0m crop_data\u001b[38;5;241m.\u001b[39mhead()\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1026\u001b[0m, in \u001b[0;36mread_csv\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[0;32m   1013\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[0;32m   1014\u001b[0m     dialect,\n\u001b[0;32m   1015\u001b[0m     delimiter,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1022\u001b[0m     dtype_backend\u001b[38;5;241m=\u001b[39mdtype_backend,\n\u001b[0;32m   1023\u001b[0m )\n\u001b[0;32m   1024\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[1;32m-> 1026\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _read(filepath_or_buffer, kwds)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:620\u001b[0m, in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    617\u001b[0m _validate_names(kwds\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnames\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[0;32m    619\u001b[0m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[1;32m--> 620\u001b[0m parser \u001b[38;5;241m=\u001b[39m TextFileReader(filepath_or_buffer, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[0;32m    622\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[0;32m    623\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1620\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m   1617\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m   1619\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles: IOHandles \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m-> 1620\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_make_engine(f, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mengine)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1880\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[1;34m(self, f, engine)\u001b[0m\n\u001b[0;32m   1878\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[0;32m   1879\u001b[0m         mode \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m-> 1880\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;241m=\u001b[39m get_handle(\n\u001b[0;32m   1881\u001b[0m     f,\n\u001b[0;32m   1882\u001b[0m     mode,\n\u001b[0;32m   1883\u001b[0m     encoding\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mencoding\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[0;32m   1884\u001b[0m     compression\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcompression\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[0;32m   1885\u001b[0m     memory_map\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmemory_map\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mFalse\u001b[39;00m),\n\u001b[0;32m   1886\u001b[0m     is_text\u001b[38;5;241m=\u001b[39mis_text,\n\u001b[0;32m   1887\u001b[0m     errors\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mencoding_errors\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstrict\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[0;32m   1888\u001b[0m     storage_options\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstorage_options\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[0;32m   1889\u001b[0m )\n\u001b[0;32m   1890\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1891\u001b[0m f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles\u001b[38;5;241m.\u001b[39mhandle\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\io\\common.py:873\u001b[0m, in \u001b[0;36mget_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[0;32m    868\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[0;32m    869\u001b[0m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[0;32m    870\u001b[0m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[0;32m    871\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mencoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mmode:\n\u001b[0;32m    872\u001b[0m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[1;32m--> 873\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(\n\u001b[0;32m    874\u001b[0m             handle,\n\u001b[0;32m    875\u001b[0m             ioargs\u001b[38;5;241m.\u001b[39mmode,\n\u001b[0;32m    876\u001b[0m             encoding\u001b[38;5;241m=\u001b[39mioargs\u001b[38;5;241m.\u001b[39mencoding,\n\u001b[0;32m    877\u001b[0m             errors\u001b[38;5;241m=\u001b[39merrors,\n\u001b[0;32m    878\u001b[0m             newline\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    879\u001b[0m         )\n\u001b[0;32m    880\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    881\u001b[0m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[0;32m    882\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(handle, ioargs\u001b[38;5;241m.\u001b[39mmode)\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '../input/crop-recommendation-dataset/Crop_recommendation.csv'"
     ]
    }
   ],
   "source": [
    "# Load the dataset\n",
    "file_path = \"../input/crop-recommendation-dataset/Crop_recommendation.csv\"\n",
    "crop_data = pd.read_csv(file_path)\n",
    "\n",
    "# Display the first few rows\n",
    "crop_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86298f1c-c1bf-45f3-8836-7229ae61ddd8",
   "metadata": {},
   "source": [
    "### Dataset Description:\n",
    "- **Rainfall (mm)**: The amount of rainfall.\n",
    "- **Soil pH**: Acidity or alkalinity of the soil.\n",
    "- **Temperature (°C)**: Average temperature.\n",
    "- **Nitrogen (N), Phosphorus (P), Potassium (K)**: Essential nutrients in the soil.\n",
    "- **Relative Humidity (%)**: The percentage of moisture in the air.\n",
    "- **Label**: The recommended crop.\n",
    "\n",
    "The dataset contains `2200 rows` and `8 columns`.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a451810-5894-4e8f-be9c-d038055d79a2",
   "metadata": {},
   "source": [
    "### Exploratory Data Analysis (EDA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c683628-3ce6-437f-ba61-2381a3c5c57a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Summary statistics\n",
    "crop_data.describe()\n",
    "\n",
    "# Check for missing values\n",
    "crop_data.isnull().sum()\n",
    "\n",
    "# Distribution of crops\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.countplot(y=crop_data['label'], order=crop_data['label'].value_counts().index)\n",
    "plt.title('Crop Distribution')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81d7786e-9750-498d-a664-5141911f227a",
   "metadata": {},
   "source": [
    "### Observations:\n",
    "- No missing values in the dataset.\n",
    "- The dataset includes diverse crops, ensuring a balanced model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ae3be75-4b0a-4ebb-97a8-0111a4b3ae91",
   "metadata": {},
   "source": [
    "### Target Labels Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6c3fb88-1259-46c2-bed0-8afb250cf7e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#   Target labels encoding\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "\n",
    "label_encoder = LabelEncoder()\n",
    "crop_data['label_encoded'] = label_encoder.fit_transform(crop_data['label'])\n",
    "\n",
    "#   Mapping btw encodaded labels and crop names\n",
    "label_mapping = {index: label for index, label in enumerate(label_encoder.classes_)}\n",
    "print(\"Label Mapping:\\n\", label_mapping)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f536bb4c-5f73-4f81-8725-6293ac01912b",
   "metadata": {},
   "source": [
    "### Data Standardization\n",
    "Standardizing the features ensures they are on the same scale, which is particularly important for models that depend on distance metrics or gradients."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46853dac-490c-490d-9f06-3d2cf2a7e696",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Separate features and target variables\n",
    "X = crop_data.drop(columns=['label', 'label_encoded'])\n",
    "y = crop_data['label_encoded']\n",
    "\n",
    "# Standardize the features\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# Log column names for reference\n",
    "print(\"Feature columns used in training:\", X.columns.to_list())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4362a31-36f0-491e-a124-c0da46eeee4a",
   "metadata": {},
   "source": [
    "## Model Training and Evaluation\n",
    "We train a Random Forest Classifier, evaluate its performance using accuracy, confusion matrix, and classification report, and visualize feature importance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fac689b7-805b-4dec-80c6-5c1b642e400b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "import numpy as np\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=42, stratify=y)\n",
    "\n",
    "# Train a Random Forest model\n",
    "random_forest = RandomForestClassifier(random_state=42, n_estimators=100)\n",
    "random_forest.fit(X_train, y_train)\n",
    "\n",
    "# Predict on the test set\n",
    "y_pred = random_forest.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "class_rept = classification_report(y_test, y_pred, target_names=label_encoder.classes_)\n",
    "conf_matx = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "# Display results\n",
    "print(f\"Model Accuracy: {accuracy * 100:.2f}%\\n\")\n",
    "print(\"Classification Report:\\n\", class_rept)\n",
    "print(\"Confusion Matrix:\\n\", conf_matx)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1a7b336-58a9-4207-a112-2002ae7fe63d",
   "metadata": {},
   "source": [
    "### Observations:\n",
    "- The model achieved an accuracy of **99.55%**.\n",
    "- Precision, recall, and F1-score are high for most crops."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc498b6a-d470-45aa-a260-659cd951c2a4",
   "metadata": {},
   "source": [
    "### Feature Importance\n",
    "Visualizing the importance of features helps us understand which features contribute the most to the predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccaa0b8a-13ee-4360-9025-0e788abd14d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature importance visualization\n",
    "feature_importance = random_forest.feature_importances_\n",
    "features = X.columns\n",
    "indices = np.argsort(feature_importance)[::-1]\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.title(\"Feature Importance\")\n",
    "plt.barh(features[indices], feature_importance[indices], align=\"center\")\n",
    "plt.xlabel(\"Relative Importance\")\n",
    "plt.ylabel(\"Features\")\n",
    "plt.gca().invert_yaxis()  # Reverse the order for better visualization\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b8c6c63-9481-4c2f-9862-5bfeec2378cc",
   "metadata": {},
   "source": [
    "## Saving and Loading the Model\n",
    "We save the trained model, scaler, and label encoder for future use. This allows us to make predictions without retraining the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd574762-eaad-4e28-a08f-c4976d9d3f74",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "# Save the model and preprocessing objects\n",
    "with open('crop_recommendation_model.pkl', 'wb') as model_file:\n",
    "    pickle.dump(random_forest, model_file)\n",
    "\n",
    "with open('scaler.pkl', 'wb') as scaler_file:\n",
    "    pickle.dump(scaler, scaler_file)\n",
    "\n",
    "with open('label_encoder.pkl', 'wb') as encoder_file:\n",
    "    pickle.dump(label_encoder, encoder_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efec92ad-44cb-40c6-9a7f-4762065bf046",
   "metadata": {},
   "source": [
    "### Loading the Saved Model\n",
    "We demonstrate how to load the saved model and use it for predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b8ad5ea-4708-4d34-b77f-19a09ba53b39",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the saved model and preprocessing objects\n",
    "with open('crop_recommendation_model.pkl', 'rb') as model_file:\n",
    "    loaded_model = pickle.load(model_file)\n",
    "\n",
    "with open('scaler.pkl', 'rb') as scaler_file:\n",
    "    loaded_scaler = pickle.load(scaler_file)\n",
    "\n",
    "with open('label_encoder.pkl', 'rb') as encoder_file:\n",
    "    loaded_encoder = pickle.load(encoder_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87753ee9-e3c3-42f3-8290-6c0f80bb817e",
   "metadata": {},
   "outputs": [],
   "source": [
    "## User Input for Prediction\n",
    "We allow users to input environmental conditions, scale the data using the saved scaler, and predict the most suitable crop."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd1cbc00-bf17-434c-a1c3-c2c7ddf0db73",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_user_input():\n",
    "    try:\n",
    "        print(\"\\nEnter the following values for prediction:\")\n",
    "        n = float(input(\"Nitrogen (N): \"))\n",
    "        p = float(input(\"Phosphorous (P): \"))\n",
    "        k = float(input(\"Potassium (K): \"))\n",
    "        temperature = float(input(\"Temperature (°C): \"))\n",
    "        humidity = float(input(\"Relative Humidity (%): \"))\n",
    "        ph = float(input(\"Soil pH: \"))\n",
    "        rainfall = float(input(\"Rainfall (mm): \"))\n",
    "\n",
    "        # Create a DataFrame with proper feature names\n",
    "        data = pd.DataFrame({\n",
    "            'N': [n],\n",
    "            'P': [p],\n",
    "            'K': [k],\n",
    "            'temperature': [temperature],\n",
    "            'humidity': [humidity],\n",
    "            'ph': [ph],\n",
    "            'rainfall': [rainfall]\n",
    "        }, columns=X.columns)  # Dynamically match training columns\n",
    "        return data\n",
    "    except ValueError:\n",
    "        print(\"Invalid inputs. Please enter numeric values only.\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82f939b3-eb04-472a-8497-8902c2ca96cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_crop(input_features, model, scaler, label_encoder):\n",
    "    if input_features is not None:\n",
    "        # Scale the features\n",
    "        scaled_features = scaler.transform(input_features)\n",
    "        # Predict using the model\n",
    "        prediction = model.predict(scaled_features)\n",
    "        # Decode predictions to crop names\n",
    "        crop_name = label_encoder.inverse_transform(prediction)\n",
    "        return crop_name[0]\n",
    "    else:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4f63fbd-9dc0-4b5b-bd07-8903ff703ed1",
   "metadata": {},
   "source": [
    "### Predicting the Crop\n",
    "Run the following cell to interactively predict the crop based on user-provided inputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3da0e3d4-fcfa-44a0-9e0f-d512279ddcac",
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    input_features = get_user_input()\n",
    "\n",
    "    if input_features is not None:\n",
    "        predicted_crop = predict_crop(input_features, loaded_model, loaded_scaler, loaded_encoder)\n",
    "        print(f\"The recommended crop for the given conditions is: {predicted_crop}\")\n",
    "    else:\n",
    "        print(\"Failed to provide valid input.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7652aa9-8bee-4773-b2aa-1f915f422c79",
   "metadata": {},
   "source": [
    "### Conclusion:\n",
    "- A Random Forest Classifier was used to predict the most suitable crop based on soil and weather conditions.\n",
    "- The model provides valuable insights for farmers and agricultural experts.\n",
    "\n",
    "### Future Work:\n",
    "- Include additional features like soil type and geographic location.\n",
    "- Deploy the model as a web application for real-time recommendations.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f15fd7f-515d-4f89-9ea7-fa859038cee6",
   "metadata": {},
   "source": [
    "### References:\n",
    "- Dataset: [Crop Recommendation Dataset](https://www.kaggle.com/datasets/atharvaingle/crop-recommendation-dataset) by Atharva Ingle.\n",
    "- Scikit-learn Documentation: https://scikit-learn.org/\n",
    "\n",
    "### Acknowledgments:\n",
    "- Thanks to Atharva Ingle for providing the dataset."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
